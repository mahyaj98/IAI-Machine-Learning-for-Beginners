{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"linear-regression-from-scratch.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"5db54414-5d84-4ce0-a483-7077a5d9fcec","_uuid":"b9a8031f5fa5d031fd810ee6c9758d8984871e3c","id":"zfWxL2yIVNE7","colab_type":"text"},"source":["#Linear Regression in the beginning\n","\n","This tutorial series is for absolute beginners in machine learning algorithms, for those who want to review/practice the fundamentals of machine learning and how to build them from scratch."]},{"cell_type":"markdown","metadata":{"_cell_guid":"dd59e88a-c8e8-4ac2-a3d3-859774c500b3","_uuid":"f8341fd36477bc7f756a3df108bcfdf68d5616b8","id":"wB5OKy2LVNFA","colab_type":"text"},"source":["## Linear Regression: Univariate\n","\n","Let's start with a very simple task of <i>linear regression</i> using a sample dataset called Portland \n","Housing Prices, wherein we are given some <i>features</i> of a house (i.e. area, no. of rooms, etc) and\n","predict the <i>target</i> price.\n","\n","To make things much simpler. Let us use only one <i>feature</i> or in this case one variable, also known as \n","<b>univariate linear regression</b>. That is we are only gonna use the 'Area' of a given house to train a\n","linear model\n","\n","<i>Let's <b>get</b> the data and <b>examine</b> it!</i>"]},{"cell_type":"code","metadata":{"_cell_guid":"43522d3c-0bd3-4047-ac96-749cf2dafdb5","_uuid":"faf52f3aedf2409551f5d28e1fb730a811cb9b92","trusted":true,"id":"Wh05yWfxVNFB","colab_type":"code","colab":{}},"source":["import numpy as np  \n","import pandas as pd "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"_cell_guid":"beb6b6c9-dc38-497c-ba43-4dce859273c5","_uuid":"7ff39de75a22ada489903fae8587ef50d77becb8","trusted":true,"id":"Q7oLzcbIVNFJ","colab_type":"code","colab":{}},"source":["data = pd.read_csv('./ex1data2.txt', header=None)\n","data.head()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"d315e841-39c0-4f5b-8765-9958dd4b3d30","_uuid":"d5a15944a4c94938d4f82d70f367dba36579512e","id":"XiHbrF1HVNFP","colab_type":"text"},"source":["The data itself does not contain feature names or labels, let's set that up first.\n","According to the source the first column is the <b>size</b> of the house in sq.ft. followed by \n","the no. of <b>bedrooms</b> and lastly the <b>price</b>."]},{"cell_type":"code","metadata":{"_cell_guid":"704267c8-4440-4b8e-8cfa-563937f24652","_uuid":"2740533589833c126f08cee08add4141ee0cdff3","trusted":true,"id":"HTOIV2TeVNFQ","colab_type":"code","colab":{}},"source":["data.columns =(['Size','Bedroom','Price'])\n","data.head()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"aee4d125-e2b4-49fe-a52a-d1a9025729ba","_uuid":"aa2d2367c5514ec1858808686d94e89e031dba0f","id":"MSVGexRnVNFV","colab_type":"text"},"source":["Let us remove the 'Bedroom' feature since we are doing <b>univariate linear regression</b>"]},{"cell_type":"code","metadata":{"scrolled":true,"_cell_guid":"2ddd0b1c-940e-40a4-81b8-9f6c3082197c","_uuid":"98997527cf4938bb758e6b859f77f560f6518e51","trusted":true,"id":"Ssj9Nx_SVNFX","colab_type":"code","colab":{}},"source":["data.drop('Bedroom', axis=1, inplace=True)\n","data.head()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"7a81626e-7097-4529-871c-2dcad4a24b21","_uuid":"166bbec8576093fdcdc9fe721dbd22a6beaf2ed8","id":"f2ygcL83VNFh","colab_type":"text"},"source":["Now that looks much <b>simpler</b>!\n","Let's <b>plot</b> our data and draw some <b>insights</b> of how a <b>linear model</b> could fit."]},{"cell_type":"code","metadata":{"_cell_guid":"1ce28d5c-2c5d-496b-a022-22dde156123c","_uuid":"3dc6dafde52ddee1f68e5d1381d12fdfb30fc48c","trusted":true,"id":"qwLQnesVVNFi","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt \n","%matplotlib inline"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"_cell_guid":"476c8d3a-4507-4db5-8ae2-0cd4be9ee149","_uuid":"5c63b9a292e630b1246b0b5c6be8fac2bd348b4c","trusted":true,"id":"eaoojQw5VNFm","colab_type":"code","colab":{}},"source":["plt.plot(data.Size, data.Price, 'r.')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"971850ed-f604-4d1f-a1a9-6fdc48a1aa8d","_uuid":"ad309122bf197fd7d0cb8577ebde45ce1de3372a","id":"klPFf3BiVNFt","colab_type":"text"},"source":["From the plot results we could see that there is a <b>high correlation</b> between Housing <b>Area</b>\n","and Housing <b>Price</b> (obviously) and therefore we could use a <b>line</b> (linear model) to fit this data."]},{"cell_type":"code","metadata":{"_cell_guid":"1dfb1102-5a4b-4404-820c-e8872993d707","_uuid":"31fe90ac10ad38a2f985c7e21fab5e3877455119","trusted":true,"id":"JrL3uMAZVNFu","colab_type":"code","colab":{}},"source":["data.corr()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"9b46a5b1-9cd8-4c87-a1e2-78d9af7aff7f","_uuid":"2ea1d6a39a765c821438db67c53ccf8a3a8f3615","id":"RuMS_dh7VNFx","colab_type":"text"},"source":["## Linear Model\n","\n","The idea of linear regression is to fit a line to a set of points.\n","So let's use the line function given by:\n","$$f(x) = y = mx + b$$\n","where <b>m</b> is the slope and <b>b</b> is our <b>y</b> intercept, or for a more general form (multiple variables)\n","$$h(x) = \\theta_0 x_0 + \\theta_1 x_1 + \\theta_2 x_2 + ... + \\theta_n x_n$$\n","such that for a single variable where <b>n = 1</b>, \n","$$h(x) = \\theta_0 + \\theta_1 x_1$$\n","$$ when \\space x_0 = 1 $$\n","where theta is our <b>parameters</b> (slope and intercept) and h(x) is our <b>hypothesis</b> or predicted value\n"]},{"cell_type":"code","metadata":{"_cell_guid":"4b948423-7ee0-4099-92cd-f1ab2afe0360","_uuid":"8b2da7760cc0597b5f43fa7bde66a01fdddbbd72","trusted":true,"id":"n2z22SfxVNFy","colab_type":"code","colab":{}},"source":["class LinearModel():\n","    \n","    def __init__(self, features, target):\n","        self.X = features\n","        self.y = target\n","    \n","    def GradDesc(self, parameters, learningRate, cost):\n","        self.a = learningRate\n","        self.c = cost\n","        self.p = parameters\n","        return self.a, self.Cost(self.c), self.p\n","    \n","    def Cost(self,c):\n","        if c =='RMSE':\n","            return self.y\n","        elif c == 'MSE':\n","            return self.X\n","            \n","            \n","X=1\n","y=0\n","a = LinearModel(5,4)\n","print(a.GradDesc(2,0.01,'MSE'))\n","print(a.Cost('RMSE'))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"42222ae1-6cbe-49a6-be65-27748e163804","_uuid":"03ef4d2c1872413a14ecef367467a9e60f577f6d","id":"rpeIdzPGVNF1","colab_type":"text"},"source":["## Matrix Math\n","\n","As it turns, using Matrices and Vectors is actually very convenient in these type of problems\n","(talking about the obvious)\n","To demonstrate that let's have an example:"]},{"cell_type":"code","metadata":{"_cell_guid":"775a9d26-7f0f-47f2-a337-155d07b636ab","_uuid":"a5bd5fe7104f4de420c5d6b8a5bd37d844a47cd8","trusted":true,"id":"dRwDfmo8VNF1","colab_type":"code","colab":{}},"source":["# given a matrix A (3x2) and a matrix B (1x2)\n","A = np.array([[1,2],\n","              [1,3],\n","              [1,4]])\n","B = np.array([[2],[3]])\n","\n","print('A =')\n","print(A,'\\nsize =',A.shape)\n","print('\\nB =')\n","print(B,'\\nsize =',B.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"f34bc186-4c4f-420c-a29e-ac33562025c6","_uuid":"92722148ab1fd4184fe01ab29fed5fcfdc75ec9e","id":"pg0n_hqlVNF4","colab_type":"text"},"source":["Suppose A is our feature matrix <b><i>X</i></b> and B as our parameter matrix <b><i>theta</i></b>, that is,\n","$$X = [\\ 1\\ 2\\ ] \\ \\ \\ \\theta = [\\ 2\\ 3\\ ]$$ \n","$$[\\ 1\\ 3\\ ] \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ $$\n","$$[\\ 1\\ 4\\ ] \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ $$\n","Remember that we have our linear model\n","$$h(x) = \\theta_0 x_0 + \\theta_1 x_1$$\n","We know that\n","$$X_0 = [\\ 1\\ ] \\ \\ \\ X_1 = [\\ 2\\ ] \\ \\ \\ \\theta^T = [\\ 2\\ ] $$ \n","$$\\ \\ \\ \\ \\ \\ \\ \\ \\ [\\ 1\\ ]\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ [\\ 3\\ ]\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ [\\ 3\\ ]$$\n","$$[\\ 1\\ ] \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ [\\ 4\\ ]\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ $$\n","then we can actually use matrix dot product to do the multiplication and addition at the same time\n","(and faster)\n","$$H=[\\ \\theta_0 X_0^0+\\theta_1 X_1^0\\ ]=[\\ \\theta_0+\\theta_1X_1^0\\ ]=[\\ 2+3(2)\\ ]=[\\ \\ 8\\ \\ ]\\ \\ \\ \\ \\ \\ \\ \\ $$\n","$$[\\ \\theta_0 X_0^1+\\theta_1 X_1^1\\ ]\\ \\ \\ \\ \\ [\\ \\theta_0+\\theta_1 X_1^1\\ ]\\ \\ \\ \\ \\ [\\ 2+3(3)\\ ]\\ \\ \\ \\ \\ [\\ 11\\ ]$$\n","$$[\\ \\theta_0 X_0^2+\\theta_1 X_1^2\\ ]\\ \\ \\ \\ \\ [\\ \\theta_0+\\theta_1 X_1^2\\ ]\\ \\ \\ \\ \\ [\\ 2+3(4)\\ ]\\ \\ \\ \\ \\ [\\ 14\\ ]$$\n","\n","$$ can\\ be\\ as\\ simple\\ as $$\n","\n","$$ H = X \\ dot \\ \\theta $$\n","<i>Yes, that is the power of <b>Matrices</b>!</i>"]},{"cell_type":"code","metadata":{"_cell_guid":"b68e3e9e-69cc-49d4-be89-3ff5775bc78c","_uuid":"b0a2dd8a3fc25349c22c31cafa5c0f100d598dc9","trusted":true,"id":"b-EKNdHgVNF4","colab_type":"code","colab":{}},"source":["# let's try it\n","H = A.dot(B)\n","print(H)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"3c362793-3327-463d-8d8e-642efc1c048e","_uuid":"5e3d9dea7416799cefdf3f60f3812f98fed94bd0","id":"7CMzaQiQVNF6","colab_type":"text"},"source":["Wow! Worked like a charm ;)"]},{"cell_type":"markdown","metadata":{"_cell_guid":"cae8f8b0-ba43-431c-b78e-8e367d3670c2","_uuid":"b128b2a803bc18459d1f2ae409bd015b7883d4c2","id":"eTe3kHKFVNF7","colab_type":"text"},"source":["## Featuring Scaling & Normalization\n","\n","Let's go back to our data and store it as <b>X</b> (features) and <b>y</b> (target) matrices first\n","also <b>m</b> (number of sample data also called 'training samples')"]},{"cell_type":"code","metadata":{"scrolled":true,"_cell_guid":"9445cd7e-1c00-47a2-9575-3281e0513263","_uuid":"aa737f1cf4537038a2905df35ea08a635baf1605","trusted":true,"id":"iMjRdHkYVNF8","colab_type":"code","colab":{}},"source":["X = np.array(data.drop('Price',axis=1))\n","y = np.array(data.Price)\n","m = len(data)\n","\n","print(X.shape)\n","print(y.shape)\n","print(m)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"2aa998d1-66e8-462a-a56a-bd8d545a3e85","_uuid":"ee676f02fa65dabd9506b6f951f03e2c40c316f8","id":"p2daGA1DVNF_","colab_type":"text"},"source":["Looking at the <b>y</b> variable, it is shaped as a flattened array <i>(47, )</i>\n","Let's reshape it to a matrix of form <i>(47, 1)</i>"]},{"cell_type":"code","metadata":{"scrolled":true,"_cell_guid":"06b7dd22-658f-4ff6-a3fd-61ba5350a7e2","_uuid":"5ed358e3f1294b2e5f1aef8bb3aa30a1e564b5ef","trusted":true,"id":"w4pwUO4wVNGA","colab_type":"code","colab":{}},"source":["y = y.reshape((m,1))\n","print(y.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"_cell_guid":"751d5551-dfa1-4846-b1a8-78b5e7244b1b","_uuid":"5ad20422072241fa0ec65bcc30d420bc9d71005b","trusted":true,"id":"gTppO5_EVNGC","colab_type":"code","colab":{}},"source":["def normscaler(Z, normal=False, scale='max'): \n","    Zn = np.zeros(Z.shape)\n","    for col in range(Zn.shape[1]):\n","        std = Z[:,col].std()\n","        clm = Z[:,col]\n","        mn = Z[:,col].mean()\n","        mx = Z[:,col].max()\n","        nrm = 0\n","        sclr = 1\n","        if normal:\n","            nrm = mn\n","        if scale =='max':\n","            sclr = mx\n","        elif scale == 'std':\n","            sclr = std\n","        Zn[:,col] = (clm-nrm)/sclr\n","        \n","    return Zn\n","    \n","Xn = normscaler(X, normal=True, scale='std')\n","yn = normscaler(y, normal=True, scale='std')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"_cell_guid":"02449954-e42d-46e6-be89-b5d8d4c6550c","_uuid":"1da472277270754a1641a141f680858acd220765","trusted":true,"id":"Z0edT4lNVNGE","colab_type":"code","colab":{}},"source":["plt.plot(Xn, yn, 'r.')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"_cell_guid":"a6ee56c4-2fe9-4662-93ca-ef2dd06ef7d2","_uuid":"128489650c606fa66a9e8ecafd096fe8a77096a0","trusted":true,"id":"KQRQYs7GVNGI","colab_type":"code","colab":{}},"source":["# parameter initialization\n","theta = np.array([0.9,-1])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"_cell_guid":"06203bf4-6983-47ed-90b0-0b00328d624d","_uuid":"7758748306294641205633a3c44edd4ddd561bbe","trusted":true,"id":"hVGsc_8gVNGM","colab_type":"code","colab":{}},"source":["lineX = np.linspace(Xn.min(), Xn.max(), 100)\n","liney = [theta[0] + theta[1]*xx for xx in lineX]\n","\n","plt.plot(Xn,yn,'r.', label='Training data')\n","plt.plot(lineX,liney,'b--', label='Current hypothesis')\n","plt.legend()\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"_cell_guid":"9bbf0c4f-a4b7-450d-aa27-48fa7e513b54","_uuid":"730e3ad7aa6480f65e8af339100dc0f2f97708c6","trusted":true,"id":"kUBpTZ7fVNGP","colab_type":"code","colab":{}},"source":["def cost_function(X, y, theta, deriv=False):\n","    z = np.ones((len(X),1))\n","    X = np.append(z, X, axis=1)\n","    \n","    if deriv:\n","        loss     = X.dot(theta)-y\n","        gradient = X.T.dot(loss)/len(X)\n","        return gradient, loss\n","        \n","    else:\n","        h = X.dot(theta)\n","        j = (h-y.flatten())\n","        J = j.dot(j)/2/(len(X))\n","        return J\n","    \n","cost_function(Xn, yn, theta)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"_cell_guid":"935cbc0f-fa58-41ad-a546-2f2565fe1c52","_uuid":"e4eff4477ebc1ea857adbd15022ceca4ec6f5a93","trusted":true,"id":"lVd3650IVNGR","colab_type":"code","colab":{}},"source":["def GradDescent(features, target, param, learnRate=0.01, multiple=1, batch=len(X), log=False):\n","\n","    iterations = batch*len(features)\n","    epochs     = iterations*multiple\n","    y          = target.flatten()\n","    t          = param\n","    b          = batch\n","    a          = learnRate\n","    \n","    theta_history  = np.zeros((param.shape[0],epochs)).T\n","    cost_history   = [0]*epochs\n","    \n","    for ix in range(epochs):\n","        \n","        i    = epochs%len(X)\n","        cost = cost_function(features[i:i+b], y[i:i+b], t)\n","\n","        cost_history[ix]   = cost\n","        theta_history[ix]  = t\n","\n","        g, l = cost_function(features[i:i+b], y[i:i+b], t, deriv=True)\n","        t    = t-a*g\n","        \n","        if log:\n","            if ix%250==0:\n","                print(\"iteration :\", ix+1)\n","                #print(\"\\tloss     = \", l)\n","                print(\"\\tgradient = \", g)\n","                print(\"\\trate     = \", a*g)\n","                print(\"\\ttheta    = \", t)\n","                print(\"\\tcost     = \", cost)\n","            \n","    return cost_history, theta_history\n","\n","alpha = 0.01\n","mul = 10\n","bat = 8\n","ch, th = GradDescent(Xn,yn,theta,alpha,mul,bat,log=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"_cell_guid":"e3162d59-9bd6-4002-b30d-9b3dc7a7b451","_uuid":"96f001195482b3deceef171dfd8e926053bf1022","trusted":true,"id":"TO-kzittVNGT","colab_type":"code","colab":{}},"source":["lineX = np.linspace(Xn.min(), Xn.max(), 100)\n","liney = [th[-1,0] + th[-1,1]*xx for xx in lineX]\n","\n","plt.plot(Xn,yn,'r.', label='Training data')\n","plt.plot(lineX,liney,'b--', label='Current hypothesis')\n","plt.legend()\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"_cell_guid":"1171ef2a-bf8e-4c66-ac37-5b43057ca80d","_uuid":"a25fcb08f1cf1d89f5884b20a6d0472d14e99b9a","trusted":true,"id":"YsDvM5dtVNGV","colab_type":"code","colab":{}},"source":["plt.plot(ch,'g--')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"_cell_guid":"4a723d32-f331-4fd3-86f4-05b993e404fa","_uuid":"f5c9f15857c2bd98aca3099519c92c16d039f61b","trusted":true,"id":"2QkpOP8aVNGX","colab_type":"code","colab":{}},"source":["plt.plot(th[:,0],'r-.')\n","plt.plot(th[:,1],'b-.')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"_cell_guid":"ca864d96-f803-43e0-a768-30b8e61cc4af","_uuid":"a98105f43909b0c3f39d198f2278cbcbb8f50b08","trusted":true,"id":"m33-dpcDVNGa","colab_type":"code","colab":{}},"source":["#Grid over which we will calculate J\n","theta0_vals = np.linspace(-2, 2, 100)\n","theta1_vals = np.linspace(-2, 3, 100)\n","\n","#initialize J_vals to a matrix of 0's\n","J_vals = np.zeros((theta0_vals.size, theta1_vals.size))\n","\n","#Fill out J_vals\n","for t1, element in enumerate(theta0_vals):\n","    for t2, element2 in enumerate(theta1_vals):\n","        thetaT = np.zeros(shape=(2, 1))\n","        thetaT[0][0] = element\n","        thetaT[1][0] = element2\n","        J_vals[t1, t2] = cost_function(Xn, yn, thetaT.flatten())\n","\n","#Contour plot\n","J_vals = J_vals.T"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"_cell_guid":"7002404e-7740-4fa7-9dce-9b45337258ac","_uuid":"098b6aebb98bdc38f5aaade59f399e974b0a2eb5","trusted":true,"id":"IEuVBojbVNGd","colab_type":"code","colab":{}},"source":["A, B = np.meshgrid(theta0_vals, theta1_vals)\n","C = J_vals\n","\n","cp = plt.contourf(A, B, C)\n","plt.colorbar(cp)\n","plt.plot(th.T[0],th.T[1],'r--')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"_cell_guid":"a388ca87-1071-43d8-8691-479badaa45e2","_uuid":"0a65bbe661c64cd87e42a6b15fe825bfd5a1239e","trusted":true,"id":"S5TA1IN2VNGi","colab_type":"code","colab":{}},"source":["#Animation\n","import matplotlib.animation as animation\n","\n","#Set the plot up,\n","fig = plt.figure(figsize=(12,5))\n","\n","plt.subplot(121)\n","plt.plot(Xn,yn,'ro', label='Training data')\n","plt.title('Housing Price Prediction')\n","plt.axis([Xn.min()-Xn.std(),Xn.max()+Xn.std(),yn.min()-yn.std(),yn.max()+yn.std()])\n","plt.grid(axis='both')\n","plt.xlabel(\"Size of house in ft^2 (X1) \")\n","plt.ylabel(\"Price in $1000s (Y)\")\n","plt.legend(loc='lower right')\n","\n","line, = plt.plot([], [], 'b-', label='Current Hypothesis')\n","annotation = plt.text(-2, 3,'',fontsize=20,color='green')\n","annotation.set_animated(True)\n","\n","plt.subplot(122)\n","cp = plt.contourf(A, B, C)\n","plt.colorbar(cp)\n","plt.title('Filled Contours Plot')\n","plt.xlabel('theta 0')\n","plt.ylabel('theta 1')\n","track, = plt.plot([], [], 'r-')\n","point, = plt.plot([], [], 'ro')\n","\n","plt.tight_layout()\n","plt.close()\n","\n","#Generate the animation data,\n","def init():\n","    line.set_data([], [])\n","    track.set_data([], [])\n","    point.set_data([], [])\n","    annotation.set_text('')\n","    return line, track, point, annotation\n","\n","# animation function.  This is called sequentially\n","def animate(i):\n","    fit1_X = np.linspace(Xn.min()-Xn.std(), Xn.max()+Xn.std(), 1000)\n","    fit1_y = th[i][0] + th[i][1]*fit1_X\n","    \n","    fit2_X = th.T[0][:i]\n","    fit2_y = th.T[1][:i]\n","    \n","    track.set_data(fit2_X, fit2_y)\n","    line.set_data(fit1_X, fit1_y)\n","    point.set_data(th.T[0][i], th.T[1][i])\n","    \n","    annotation.set_text('Cost = %.4f' %(ch[i]))\n","    return line, track, point, annotation\n","\n","anim = animation.FuncAnimation(fig, animate, init_func=init,\n","                               frames=800, interval=0, blit=True)\n","\n","anim.save('animation.gif', writer='imagemagick', fps = 30)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"_kg_hide-input":false,"_kg_hide-output":false,"_uuid":"3770aa329a2c0fe3cf9e074892701d8718f24485","scrolled":false,"_cell_guid":"4edef8df-add8-4546-b1f7-e57c691713ee","trusted":true,"id":"0pMvxiluVNGk","colab_type":"code","colab":{}},"source":["import io\n","import base64\n","from IPython.display import HTML\n","\n","filename = 'animation.gif'\n","\n","video = io.open(filename, 'r+b').read()\n","encoded = base64.b64encode(video)\n","HTML(data='''<img src=\"data:image/gif;base64,{0}\" type=\"gif\" />'''.format(encoded.decode('ascii')))"],"execution_count":0,"outputs":[]}]}