{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SVM_SCRATCH.ipynb","version":"0.3.2","provenance":[],"private_outputs":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"2ejtGvngtU8n","colab_type":"code","colab":{}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","np.random.seed(6)\n","import math"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XwFmAn54tmwQ","colab_type":"code","colab":{}},"source":["from sklearn.datasets.samples_generator import make_blobs\n","\n","(X,y) =  make_blobs(n_samples=50,n_features=2,centers=2,cluster_std=1.05,random_state=40)\n","#we need to add 1 to X values (we can say its bias)\n","X1 = np.c_[np.ones((X.shape[0])),X]\n","\n","plt.scatter(X1[:,1],X1[:,2],marker='o',c=y)\n","plt.axis([-5,10,-12,-1])\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ym247VpJtpUk","colab_type":"code","colab":{}},"source":["postiveX=[]\n","negativeX=[]\n","for i,v in enumerate(y):\n","    if v==0:\n","        negativeX.append(X[i])\n","    else:\n","        postiveX.append(X[i])\n","\n","#our data dictionary\n","data_dict = {-1:np.array(negativeX), 1:np.array(postiveX)}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RaltasTYtrSP","colab_type":"code","colab":{}},"source":["#all the required variables \n","w=[] #weights 2 dimensional vector\n","b=[] #bias\n","\n","max_feature_value=float('-inf')\n","min_feature_value=float('+inf')\n","        \n","for yi in data_dict:\n","    if np.amax(data_dict[yi])>max_feature_value:\n","        max_feature_value=np.amax(data_dict[yi])\n","                \n","    if np.amin(data_dict[yi])<min_feature_value:\n","        min_feature_value=np.amin(data_dict[yi])\n","        \n","learning_rate = [max_feature_value * 0.1, max_feature_value * 0.01, max_feature_value * 0.001,]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bRm4MxTuttDg","colab_type":"code","colab":{}},"source":["def SVM_Training(data_dict):\n","    i=1\n","    global w\n","    global b\n","    # { ||w||: [w,b] }\n","    length_Wvector = {}\n","    transforms = [[1,1],[-1,1],[-1,-1],[1,-1]]\n","    \n","    b_step_size = 2\n","    b_multiple = 5\n","    w_optimum = max_feature_value*0.5\n","\n","    for lrate in learning_rate:\n","        \n","        w = np.array([w_optimum,w_optimum])     \n","        optimized = False\n","        while not optimized:\n","            #b=[-maxvalue to maxvalue] we wanna maximize the b values so check for every b value\n","            for b in np.arange(-1*(max_feature_value*b_step_size), max_feature_value*b_step_size, lrate*b_multiple):\n","                for transformation in transforms:  # transforms = [[1,1],[-1,1],[-1,-1],[1,-1]]\n","                    w_t = w*transformation\n","                    \n","                    correctly_classified = True\n","                    \n","                    # every data point should be correct\n","                    for yi in data_dict:\n","                        for xi in data_dict[yi]:\n","                            if yi*(np.dot(w_t,xi)+b) < 1:  # we want  yi*(np.dot(w_t,xi)+b) >= 1 for correct classification\n","                                correctly_classified = False\n","                                \n","                    if correctly_classified:\n","                        length_Wvector[np.linalg.norm(w_t)] = [w_t,b] #store w, b for minimum magnitude\n","            \n","            if w[0] < 0:\n","                optimized = True\n","            else:\n","                w = w - lrate\n","\n","        norms = sorted([n for n in length_Wvector])\n","        \n","        minimum_wlength = length_Wvector[norms[0]]\n","        w = minimum_wlength[0]\n","        b = minimum_wlength[1]\n","        \n","        w_optimum = w[0]+lrate*2"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"M6WP24Xnt1ho","colab_type":"code","colab":{}},"source":["SVM_Training(data_dict)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CLvFcdrAt2Dt","colab_type":"code","colab":{}},"source":["colors = {1:'r',-1:'b'}\n","fig = plt.figure()\n","ax = fig.add_subplot(1,1,1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9K-bEGvQvvz5","colab_type":"code","colab":{}},"source":["def visualize(data_dict):\n","       \n","        \n","        #[[ax.scatter(x[0],x[1],s=100,color=colors[i]) for x in data_dict[i]] for i in data_dict]\n","        \n","        plt.scatter(X1[:,1],X1[:,2],marker='o',c=y)\n","\n","        # hyperplane = x.w+b\n","        # v = x.w+b\n","        # psv = 1\n","        # nsv = -1\n","        # dec = 0\n","        def hyperplane_value(x,w,b,v):\n","            return (-w[0]*x-b+v) / w[1]\n","\n","        datarange = (min_feature_value*0.9,max_feature_value*1.)\n","        hyp_x_min = datarange[0]\n","        hyp_x_max = datarange[1]\n","\n","        # (w.x+b) = 1\n","        # positive support vector hyperplane\n","        psv1 = hyperplane_value(hyp_x_min, w, b, 1)\n","        psv2 = hyperplane_value(hyp_x_max, w, b, 1)\n","        ax.plot([hyp_x_min,hyp_x_max],[psv1,psv2], 'k')\n","\n","        # (w.x+b) = -1\n","        # negative support vector hyperplane\n","        nsv1 = hyperplane_value(hyp_x_min, w, b, -1)\n","        nsv2 = hyperplane_value(hyp_x_max, w, b, -1)\n","        ax.plot([hyp_x_min,hyp_x_max],[nsv1,nsv2], 'k')\n","\n","        # (w.x+b) = 0\n","        # positive support vector hyperplane\n","        db1 = hyperplane_value(hyp_x_min, w, b, 0)\n","        db2 = hyperplane_value(hyp_x_max, w, b, 0)\n","        ax.plot([hyp_x_min,hyp_x_max],[db1,db2], 'y--')\n","        \n","        plt.axis([-5,10,-12,-1])\n","        plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IhMq2aobv04u","colab_type":"code","colab":{}},"source":["visualize(data_dict)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vmBH480Xv3Cy","colab_type":"code","colab":{}},"source":["def predict(features):\n","        # sign( x.w+b )\n","        dot_result = np.sign(np.dot(np.array(features),w)+b)\n","        return dot_result.astype(int)\n","    \n","for i in X[:5]:\n","    print(predict(i),end=',  ')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nlYz3YmJv5Do","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}